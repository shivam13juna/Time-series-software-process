{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32m0_download_dataset.py\u001b[0m*       \u001b[01;32mchickenbestlover.ipynb\u001b[0m*  \u001b[34;42m__pycache__\u001b[0m/\n",
      "\u001b[01;32m1_train_predictor_all.sh\u001b[0m*    \u001b[34;42mdataset\u001b[0m/                 \u001b[01;32mREADME.md\u001b[0m*\n",
      "\u001b[01;32m1_train_predictor.py\u001b[0m*        \u001b[34;42mfig\u001b[0m/                     \u001b[01;32mrequirements.txt\u001b[0m*\n",
      "\u001b[01;32m2_anomaly_detection_all.sh\u001b[0m*  \u001b[01;32mLICENSE\u001b[0m*                 \u001b[34;42mresult\u001b[0m/\n",
      "\u001b[01;32m2_anomaly_detection.py\u001b[0m*      \u001b[34;42mmodel\u001b[0m/                   \u001b[34;42msave\u001b[0m/\n",
      "\u001b[01;32manomalyDetector.py\u001b[0m*          \u001b[01;32mpng2gif.py\u001b[0m*              \u001b[01;32mtest_dataset\u001b[0m*\n",
      "\u001b[01;32mbata.csv\u001b[0m*                    \u001b[01;32mpreprocess_data.py\u001b[0m*      \u001b[01;32mtrain_dataset\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import preprocess_data\n",
    "from model import model\n",
    "from torch import optim\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from anomalyDetector import fit_norm_distribution_param\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = ['vnf label', 'vnf min cpu', 'vnf min mem', 'vnf min sto', 'vnf vm cpu',\n",
    "       'vnf vm mem', 'vnf vm sto', 'vnf pm id', 'vnf cpu usage',\n",
    "       'vnf mem usage', 'vnf sto usage', 'vnf before', 'vnf after',\n",
    "       'vnf label.1', 'vnf min cpu.1', 'vnf min mem.1', 'vnf min sto.1',\n",
    "       'vnf vm cpu.1', 'vnf vm mem.1', 'vnf vm sto.1', 'vnf pm id.1',\n",
    "       'vnf cpu usage.1', 'vnf mem usage.1', 'vnf sto usage.1', 'vnf before.1',\n",
    "       'vnf after.1', 'sla', 'fg id', 'flow traffic', 'flow latency',\n",
    "       'flow bnd usage', 'flow packet loss', 'min cpu affinity',\n",
    "       'min mem affinity', 'min sto affinity', 'conflicts affinity',\n",
    "       'real_affinity', 'static_affinity', 'predicted_affinity',\n",
    "       'prediction_time', 'TF', 'MTT', 'MTT_upper', 'MTT_lower', 'MTTF_R',\n",
    "       'MTTF_EM', 'MTTF_C', 'MTTF_TDDB', 'MTTF_SM', 'MTTFF_TC', 'A', 'AEM',\n",
    "       'AC', 'ATDDB', 'ASM', 'ATC', 'TAA', 'QRED', 'QR', 'PUE', 'DCie', 'cost',\n",
    "       'TIMESTAMP', 'EXTERNAL_TEMP', 'ROOM_TEMP', 'MTTF_IC', 'A_TC', 'Q_DIT',\n",
    "       'TPF', 'AIRFLOW', 'TAAF', 'DeltaT_de', 'QD']\n",
    "       \n",
    "       \n",
    "#Select your global variable among one of above, and place it after base below\n",
    "\n",
    "\n",
    "base = 'vnf cpu usage'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs = pd.read_csv('../fgs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>4963594775</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>proxy.9.5698</th>\n",
       "      <th>traffic counter.7.5664</th>\n",
       "      <th>0.971442</th>\n",
       "      <th>82.243099</th>\n",
       "      <td>1.794354</td>\n",
       "      <td>9.341767</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402488769</th>\n",
       "      <th>5</th>\n",
       "      <th>1.000000</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traffic counter.7.7413</th>\n",
       "      <th>proxy.9.11244</th>\n",
       "      <th>4.060322</th>\n",
       "      <th>119.086081</th>\n",
       "      <td>16.548350</td>\n",
       "      <td>8.474562</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proxy.9.11244</th>\n",
       "      <th>proxy.9.2362</th>\n",
       "      <th>0.268318</th>\n",
       "      <th>23.865256</th>\n",
       "      <td>11.573841</td>\n",
       "      <td>9.248256</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proxy.9.2362</th>\n",
       "      <th>traffic counter.7.9524</th>\n",
       "      <th>2.961259</th>\n",
       "      <th>80.083566</th>\n",
       "      <td>18.280812</td>\n",
       "      <td>4.783467</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   4963594775  \\\n",
       "proxy.9.5698           traffic counter.7.5664 0.971442 82.243099     1.794354   \n",
       "5402488769             5                      1.000000 NaN                NaN   \n",
       "traffic counter.7.7413 proxy.9.11244          4.060322 119.086081   16.548350   \n",
       "proxy.9.11244          proxy.9.2362           0.268318 23.865256    11.573841   \n",
       "proxy.9.2362           traffic counter.7.9524 2.961259 80.083566    18.280812   \n",
       "\n",
       "                                                                          1  \\\n",
       "proxy.9.5698           traffic counter.7.5664 0.971442 82.243099   9.341767   \n",
       "5402488769             5                      1.000000 NaN              NaN   \n",
       "traffic counter.7.7413 proxy.9.11244          4.060322 119.086081  8.474562   \n",
       "proxy.9.11244          proxy.9.2362           0.268318 23.865256   9.248256   \n",
       "proxy.9.2362           traffic counter.7.9524 2.961259 80.083566   4.783467   \n",
       "\n",
       "                                                                       2  \n",
       "proxy.9.5698           traffic counter.7.5664 0.971442 82.243099   100.0  \n",
       "5402488769             5                      1.000000 NaN           NaN  \n",
       "traffic counter.7.7413 proxy.9.11244          4.060322 119.086081  150.0  \n",
       "proxy.9.11244          proxy.9.2362           0.268318 23.865256   150.0  \n",
       "proxy.9.2362           traffic counter.7.9524 2.961259 80.083566   150.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vns = pd.read_csv('../vnfs.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnf_id = vns[vns.columns[0]]\n",
    "vnf_type = vns[vns.columns[1]]\n",
    "vnf_scheduling = vns[vns.columns[2]]\n",
    "vnf_pm = vns[vns.columns[3]]\n",
    "vnf_fg = vns[vns.columns[4]]\n",
    "flavor_data = vns[vns.columns[5:8]]\n",
    "vm_data = vns[vns.columns[8:11]]\n",
    "usage_data = vns[vns.columns[11:15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv('../new_results_out.csv', sep =';')#header=None)\n",
    "output.drop('Unnamed: 0',axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vnf label</th>\n",
       "      <th>vnf min cpu</th>\n",
       "      <th>vnf min mem</th>\n",
       "      <th>vnf min sto</th>\n",
       "      <th>vnf vm cpu</th>\n",
       "      <th>vnf vm mem</th>\n",
       "      <th>vnf vm sto</th>\n",
       "      <th>vnf pm id</th>\n",
       "      <th>vnf cpu usage</th>\n",
       "      <th>vnf mem usage</th>\n",
       "      <th>...</th>\n",
       "      <th>EXTERNAL_TEMP</th>\n",
       "      <th>ROOM_TEMP</th>\n",
       "      <th>MTTF_IC</th>\n",
       "      <th>A_TC</th>\n",
       "      <th>Q_DIT</th>\n",
       "      <th>TPF</th>\n",
       "      <th>AIRFLOW</th>\n",
       "      <th>TAAF</th>\n",
       "      <th>DeltaT_de</th>\n",
       "      <th>QD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dpi.2.136144</td>\n",
       "      <td>0.035914</td>\n",
       "      <td>0.226393</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.12720</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>257345416</td>\n",
       "      <td>71.88000</td>\n",
       "      <td>1.75780</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>2435.249666</td>\n",
       "      <td>0.996726</td>\n",
       "      <td>1.839678</td>\n",
       "      <td>14.999377</td>\n",
       "      <td>0.131858</td>\n",
       "      <td>0.872117</td>\n",
       "      <td>6.132259</td>\n",
       "      <td>6.132259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traffic counter.7.40368</td>\n",
       "      <td>0.063818</td>\n",
       "      <td>0.017674</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.06189</td>\n",
       "      <td>0.03821</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>3488796635</td>\n",
       "      <td>3.51600</td>\n",
       "      <td>6.34800</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>49.077683</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>1.801941</td>\n",
       "      <td>14.999402</td>\n",
       "      <td>0.142946</td>\n",
       "      <td>0.768427</td>\n",
       "      <td>6.006469</td>\n",
       "      <td>6.006469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proxy.9.13456</td>\n",
       "      <td>0.018672</td>\n",
       "      <td>0.020912</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.01250</td>\n",
       "      <td>0.01590</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>4820294844</td>\n",
       "      <td>0.18044</td>\n",
       "      <td>0.13352</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>82.372536</td>\n",
       "      <td>0.911478</td>\n",
       "      <td>1.800100</td>\n",
       "      <td>54.999420</td>\n",
       "      <td>0.152569</td>\n",
       "      <td>0.757640</td>\n",
       "      <td>6.000332</td>\n",
       "      <td>6.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firewall.3.36933</td>\n",
       "      <td>0.140469</td>\n",
       "      <td>0.021706</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.03198</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>3550430599</td>\n",
       "      <td>26.46000</td>\n",
       "      <td>6.44600</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>0.044220</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>1.814606</td>\n",
       "      <td>39.999481</td>\n",
       "      <td>0.132889</td>\n",
       "      <td>0.807089</td>\n",
       "      <td>6.048686</td>\n",
       "      <td>6.048686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dpi.2.92594</td>\n",
       "      <td>0.015708</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.08569</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>4820072706</td>\n",
       "      <td>41.74000</td>\n",
       "      <td>14.42800</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>1.823040</td>\n",
       "      <td>20.999427</td>\n",
       "      <td>0.189031</td>\n",
       "      <td>0.790021</td>\n",
       "      <td>6.076802</td>\n",
       "      <td>6.076802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 vnf label  vnf min cpu  vnf min mem  vnf min sto  vnf vm cpu  \\\n",
       "0             dpi.2.136144     0.035914     0.226393     0.001757     0.06250   \n",
       "1  traffic counter.7.40368     0.063818     0.017674     0.000223     0.06189   \n",
       "2            proxy.9.13456     0.018672     0.020912     0.000006     0.01250   \n",
       "3         firewall.3.36933     0.140469     0.021706     0.000068     0.09375   \n",
       "4              dpi.2.92594     0.015708     0.050654     0.000810     0.06250   \n",
       "\n",
       "   vnf vm mem  vnf vm sto   vnf pm id  vnf cpu usage  vnf mem usage  ...  \\\n",
       "0     0.12720    0.001930   257345416       71.88000        1.75780  ...   \n",
       "1     0.03821    0.000386  3488796635        3.51600        6.34800  ...   \n",
       "2     0.01590    0.000404  4820294844        0.18044        0.13352  ...   \n",
       "3     0.03198    0.000070  3550430599       26.46000        6.44600  ...   \n",
       "4     0.08569    0.000926  4820072706       41.74000       14.42800  ...   \n",
       "\n",
       "   EXTERNAL_TEMP ROOM_TEMP      MTTF_IC      A_TC     Q_DIT        TPF  \\\n",
       "0             15        23  2435.249666  0.996726  1.839678  14.999377   \n",
       "1             15        24    49.077683  0.859840  1.801941  14.999402   \n",
       "2             55        25    82.372536  0.911478  1.800100  54.999420   \n",
       "3             40        23     0.044220  0.005497  1.814606  39.999481   \n",
       "4             21        29     0.011200  0.001398  1.823040  20.999427   \n",
       "\n",
       "    AIRFLOW      TAAF  DeltaT_de        QD  \n",
       "0  0.131858  0.872117   6.132259  6.132259  \n",
       "1  0.142946  0.768427   6.006469  6.006469  \n",
       "2  0.152569  0.757640   6.000332  6.000332  \n",
       "3  0.132889  0.807089   6.048686  6.048686  \n",
       "4  0.189031  0.790021   6.076802  6.076802  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vnf label', 'vnf min cpu', 'vnf min mem', 'vnf min sto', 'vnf vm cpu',\n",
       "       'vnf vm mem', 'vnf vm sto', 'vnf pm id', 'vnf cpu usage',\n",
       "       'vnf mem usage', 'vnf sto usage', 'vnf before', 'vnf after',\n",
       "       'vnf label.1', 'vnf min cpu.1', 'vnf min mem.1', 'vnf min sto.1',\n",
       "       'vnf vm cpu.1', 'vnf vm mem.1', 'vnf vm sto.1', 'vnf pm id.1',\n",
       "       'vnf cpu usage.1', 'vnf mem usage.1', 'vnf sto usage.1', 'vnf before.1',\n",
       "       'vnf after.1', 'sla', 'fg id', 'flow traffic', 'flow latency',\n",
       "       'flow bnd usage', 'flow packet loss', 'min cpu affinity',\n",
       "       'min mem affinity', 'min sto affinity', 'conflicts affinity',\n",
       "       'real_affinity', 'static_affinity', 'predicted_affinity',\n",
       "       'prediction_time', 'TF', 'MTT', 'MTT_upper', 'MTT_lower', 'MTTF_R',\n",
       "       'MTTF_EM', 'MTTF_C', 'MTTF_TDDB', 'MTTF_SM', 'MTTFF_TC', 'A', 'AEM',\n",
       "       'AC', 'ATDDB', 'ASM', 'ATC', 'TAA', 'QRED', 'QR', 'PUE', 'DCie', 'cost',\n",
       "       'TIMESTAMP', 'EXTERNAL_TEMP', 'ROOM_TEMP', 'MTTF_IC', 'A_TC', 'Q_DIT',\n",
       "       'TPF', 'AIRFLOW', 'TAAF', 'DeltaT_de', 'QD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195379,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[base].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output[:12322]\n",
    "output = output[base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.stack((output, vnf_id, np.zeros(len(vnf_id))), axis = 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[71.88, 126.0, 0.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_dataset','wb') as pkl:\n",
    "    pickle.dump(dataset[:12000], pkl)\n",
    "    \n",
    "with open('test_dataset','wb') as pkl:\n",
    "    pickle.dump(dataset[12000:], pkl)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_dataset = vns[:10000]\n",
    "trainy = output[:10000]\n",
    "\n",
    "test_dataset = vns[10000:]\n",
    "testy = output[10000:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data='ecg'\n",
    "filename='chfdb_chf13_45590.pkl'\n",
    "model_name='LSTM'\n",
    "augment=True\n",
    "emsize=32\n",
    "nhid=32         \n",
    "nlayers=2\n",
    "res_connection='store_true'\n",
    "lr=0.0002\n",
    "weight_decay=1e-4\n",
    "clip=10\n",
    "epochs=400\n",
    "batch_size=64\n",
    "eval_batch_size=64\n",
    "bptt=50\n",
    "teacher_forcing_ratio=0.7\n",
    "dropout=0.2\n",
    "tied='store_true'\n",
    "seed=1111\n",
    "device='cuda'\n",
    "log_interval=10\n",
    "save_interval=10\n",
    "save_fig='store_true'\n",
    "resume=False\n",
    "pretrained=False\n",
    "prediction_window_size=10"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature_dim = 15"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = model.RNNPredictor(rnn_type = model_name,\n",
    "                           enc_inp_size=feature_dim,\n",
    "                           rnn_inp_size = emsize,\n",
    "                           rnn_hid_size = nhid,\n",
    "                           dec_out_size=feature_dim,\n",
    "                           nlayers = nlayers,\n",
    "                           dropout = dropout,\n",
    "                           tie_weights= tied,\n",
    "                           res_connection=res_connection).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr= lr,weight_decay=weight_decay)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "def get_batch(args,source, i):\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len] # [ seq_len * batch_size * feature_size ]\n",
    "    target = source[i+1:i+1+seq_len] # [ (seq_len x batch_size x feature_size) ]\n",
    "    return data, target\n",
    "\n",
    "def generate_output(args,epoch, model, gen_dataset, disp_uncertainty=True,startPoint=500, endPoint=3500):\n",
    "    if save_fig:\n",
    "        # Turn on evaluation mode which disables dropout.\n",
    "        model.eval()\n",
    "        hidden = model.init_hidden(1)\n",
    "        outSeq = []\n",
    "        upperlim95 = []\n",
    "        lowerlim95 = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(endPoint):\n",
    "                if i>=startPoint:\n",
    "                    # if disp_uncertainty and epoch > 40:\n",
    "                    #     outs = []\n",
    "                    #     model.train()\n",
    "                    #     for i in range(20):\n",
    "                    #         out_, hidden_ = model.forward(out+0.01*Variable(torch.randn(out.size())).cuda(),hidden,noise=True)\n",
    "                    #         outs.append(out_)\n",
    "                    #     model.eval()\n",
    "                    #     outs = torch.cat(outs,dim=0)\n",
    "                    #     out_mean = torch.mean(outs,dim=0) # [bsz * feature_dim]\n",
    "                    #     out_std = torch.std(outs,dim=0) # [bsz * feature_dim]\n",
    "                    #     upperlim95.append(out_mean + 2.58*out_std/np.sqrt(20))\n",
    "                    #     lowerlim95.append(out_mean - 2.58*out_std/np.sqrt(20))\n",
    "\n",
    "                    out, hidden = model.forward(out, hidden)\n",
    "\n",
    "                    #print(out_mean,out)\n",
    "\n",
    "                else:\n",
    "                    out, hidden = model.forward(gen_dataset[i].unsqueeze(0), hidden)\n",
    "                outSeq.append(out.data.cpu()[0][0].unsqueeze(0))\n",
    "\n",
    "\n",
    "        outSeq = torch.cat(outSeq,dim=0) # [seqLength * feature_dim]\n",
    "\n",
    "        target= preprocess_data.reconstruct(gen_dataset.cpu(), TimeseriesData.mean, TimeseriesData.std)\n",
    "        outSeq = preprocess_data.reconstruct(outSeq, TimeseriesData.mean, TimeseriesData.std)\n",
    "        # if epoch>40:\n",
    "        #     upperlim95 = torch.cat(upperlim95, dim=0)\n",
    "        #     lowerlim95 = torch.cat(lowerlim95, dim=0)\n",
    "        #     upperlim95 = preprocess_data.reconstruct(upperlim95.data.cpu().numpy(),TimeseriesData.mean,TimeseriesData.std)\n",
    "        #     lowerlim95 = preprocess_data.reconstruct(lowerlim95.data.cpu().numpy(),TimeseriesData.mean,TimeseriesData.std)\n",
    "\n",
    "        plt.figure(figsize=(15,5))\n",
    "        for i in range(target.size(-1)):\n",
    "            plt.plot(target[:,:,i].numpy(), label='Target'+str(i),\n",
    "                     color='black', marker='.', linestyle='--', markersize=1, linewidth=0.5)\n",
    "            plt.plot(range(startPoint), outSeq[:startPoint,i].numpy(), label='1-step predictions for target'+str(i),\n",
    "                     color='green', marker='.', linestyle='--', markersize=1.5, linewidth=1)\n",
    "            # if epoch>40:\n",
    "            #     plt.plot(range(startPoint, endPoint), upperlim95[:,i].numpy(), label='upperlim'+str(i),\n",
    "            #              color='skyblue', marker='.', linestyle='--', markersize=1.5, linewidth=1)\n",
    "            #     plt.plot(range(startPoint, endPoint), lowerlim95[:,i].numpy(), label='lowerlim'+str(i),\n",
    "            #              color='skyblue', marker='.', linestyle='--', markersize=1.5, linewidth=1)\n",
    "            plt.plot(range(startPoint, endPoint), outSeq[startPoint:,i].numpy(), label='Recursive predictions for target'+str(i),\n",
    "                     color='blue', marker='.', linestyle='--', markersize=1.5, linewidth=1)\n",
    "\n",
    "        plt.xlim([startPoint-500, endPoint])\n",
    "        plt.xlabel('Index',fontsize=15)\n",
    "        plt.ylabel('Value',fontsize=15)\n",
    "        plt.title('Time-series Prediction on ' + data + ' Dataset', fontsize=18, fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.text(startPoint-500+10, target.min(), 'Epoch: '+str(epoch),fontsize=15)\n",
    "        save_dir = Path('result',data,filename).with_suffix('').joinpath('fig_prediction')\n",
    "        save_dir.mkdir(parents=True,exist_ok=True)\n",
    "        plt.savefig(save_dir.joinpath('fig_epoch'+str(epoch)).with_suffix('.png'))\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "        return outSeq\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_1step_pred(args, model, test_dataset):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        hidden = model.init_hidden(eval_batch_size)\n",
    "        for nbatch, i in enumerate(range(0, test_dataset.size(0) - 1, bptt)):\n",
    "\n",
    "            inputSeq, targetSeq = get_batch(args,test_dataset, i)\n",
    "            outSeq, hidden = model.forward(inputSeq, hidden)\n",
    "\n",
    "            loss = criterion(outSeq.view(batch_size,-1), targetSeq.view(batch_size,-1))\n",
    "            hidden = model.repackage_hidden(hidden)\n",
    "            total_loss+= loss.item()\n",
    "\n",
    "    return total_loss / nbatch\n",
    "\n",
    "def train(model, train_dataset,epoch):\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        # Turn on training mode which enables dropout.\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        start_time = time.time()\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        for batch, i in enumerate(range(0, train_dataset.size(0) - 1, bptt)):\n",
    "            inputSeq, targetSeq = get_batch(args,train_dataset, i)\n",
    "            # inputSeq: [ seq_len * batch_size * feature_size ]\n",
    "            # targetSeq: [ seq_len * batch_size * feature_size ]\n",
    "\n",
    "            # Starting each batch, we detach the hidden state from how it was previously produced.\n",
    "            # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
    "            hidden = model.repackage_hidden(hidden)\n",
    "            hidden_ = model.repackage_hidden(hidden)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            '''Loss1: Free running loss'''\n",
    "            outVal = inputSeq[0].unsqueeze(0)\n",
    "            outVals=[]\n",
    "            hids1 = []\n",
    "            for i in range(inputSeq.size(0)):\n",
    "                outVal, hidden_, hid = model.forward(outVal, hidden_,return_hiddens=True)\n",
    "                outVals.append(outVal)\n",
    "                hids1.append(hid)\n",
    "            outSeq1 = torch.cat(outVals,dim=0)\n",
    "            hids1 = torch.cat(hids1,dim=0)\n",
    "            loss1 = criterion(outSeq1.view(batch_size,-1), targetSeq.view(batch_size,-1))\n",
    "\n",
    "            '''Loss2: Teacher forcing loss'''\n",
    "            outSeq2, hidden, hids2 = model.forward(inputSeq, hidden, return_hiddens=True)\n",
    "            loss2 = criterion(outSeq2.view(batch_size, -1), targetSeq.view(batch_size, -1))\n",
    "\n",
    "            '''Loss3: Simplified Professor forcing loss'''\n",
    "            loss3 = criterion(hids1.view(batch_size,-1), hids2.view(batch_size,-1).detach())\n",
    "\n",
    "            '''Total loss = Loss1+Loss2+Loss3'''\n",
    "            loss = loss1+loss2+loss3\n",
    "            loss.backward()\n",
    "\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if batch % log_interval == 0 and batch > 0:\n",
    "                cur_loss = total_loss / log_interval\n",
    "                elapsed = time.time() - start_time\n",
    "                print('| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.4f} | '\n",
    "                      'loss {:5.2f} '.format(\n",
    "                    epoch, batch, len(train_dataset) // bptt,\n",
    "                                  elapsed * 1000 / log_interval, cur_loss))\n",
    "                total_loss = 0\n",
    "                start_time = time.time()\n",
    "\n",
    "def evaluate(args, model, test_dataset):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        hidden = model.init_hidden(eval_batch_size)\n",
    "        nbatch = 1\n",
    "        for nbatch, i in enumerate(range(0, test_dataset.size(0) - 1, bptt)):\n",
    "            inputSeq, targetSeq = get_batch(args,test_dataset, i)\n",
    "            # inputSeq: [ seq_len * batch_size * feature_size ]\n",
    "            # targetSeq: [ seq_len * batch_size * feature_size ]\n",
    "            hidden_ = model.repackage_hidden(hidden)\n",
    "            '''Loss1: Free running loss'''\n",
    "            outVal = inputSeq[0].unsqueeze(0)\n",
    "            outVals=[]\n",
    "            hids1 = []\n",
    "            for i in range(inputSeq.size(0)):\n",
    "                outVal, hidden_, hid = model.forward(outVal, hidden_,return_hiddens=True)\n",
    "                outVals.append(outVal)\n",
    "                hids1.append(hid)\n",
    "            outSeq1 = torch.cat(outVals,dim=0)\n",
    "            hids1 = torch.cat(hids1,dim=0)\n",
    "            loss1 = criterion(outSeq1.view(batch_size,-1), targetSeq.view(batch_size,-1))\n",
    "\n",
    "            '''Loss2: Teacher forcing loss'''\n",
    "            outSeq2, hidden, hids2 = model.forward(inputSeq, hidden, return_hiddens=True)\n",
    "            loss2 = criterion(outSeq2.view(batch_size, -1), targetSeq.view(batch_size, -1))\n",
    "\n",
    "            '''Loss3: Simplified Professor forcing loss'''\n",
    "            loss3 = criterion(hids1.view(batch_size,-1), hids2.view(batch_size,-1).detach())\n",
    "\n",
    "            '''Total loss = Loss1+Loss2+Loss3'''\n",
    "            loss = loss1+loss2+loss3\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / (nbatch+1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Loop over epochs.\n",
    "if resume or pretrained:\n",
    "    print(\"=> loading checkpoint \")\n",
    "    checkpoint = torch.load(Path('save', data, 'checkpoint', filename).with_suffix('.pth'))\n",
    "    args, start_epoch, best_val_loss = model.load_checkpoint(args,checkpoint,feature_dim)\n",
    "    optimizer.load_state_dict((checkpoint['optimizer']))\n",
    "    del checkpoint\n",
    "    epoch = start_epoch\n",
    "    print(\"=> loaded checkpoint\")\n",
    "else:\n",
    "    epoch = 100\n",
    "    start_epoch = 1\n",
    "    best_val_loss = 0\n",
    "    print(\"=> Start training from scratch\")\n",
    "\n",
    "\n",
    "if not pretrained:\n",
    "    # At any point you can hit Ctrl + C to break out of training early.\n",
    "    try:\n",
    "        for epoch in range(start_epoch, epochs+1):\n",
    "\n",
    "            epoch_start_time = time.time()\n",
    "            train(model,train_dataset,epoch)\n",
    "            val_loss = evaluate(args,model,test_dataset)\n",
    "            print('-' * 89)\n",
    "            print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.4f} | '.format(epoch, (time.time() - epoch_start_time),                                                                                        val_loss))\n",
    "            print('-' * 89)\n",
    "\n",
    "     r       generate_output(args,epoch,model,gen_dataset,startPoint=1500)\n",
    "\n",
    "            if epoch%save_interval==0:\n",
    "                # Save the model if the validation loss is the best we've seen so far.\n",
    "                is_best = val_loss > best_val_loss\n",
    "                best_val_loss = max(val_loss, best_val_loss)\n",
    "                model_dictionary = {'epoch': epoch,\n",
    "                                    'best_loss': best_val_loss,\n",
    "                                    'state_dict': model.state_dict(),\n",
    "                                    'optimizer': optimizer.state_dict(),\n",
    "                                    'args':args\n",
    "                                    }\n",
    "                model.save_checkpoint(model_dictionary, is_best)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('-' * 89)\n",
    "        print('Exiting from training early')\n",
    "\n",
    "\n",
    "# Calculate mean and covariance for each channel's prediction errors, and save them with the trained model\n",
    "print('=> calculating mean and covariance')\n",
    "means, covs = list(),list()\n",
    "train_dataset = TimeseriesData.batchify(args, TimeseriesData.trainData, bsz=1)\n",
    "for channel_idx in range(model.enc_input_size):\n",
    "    mean, cov = fit_norm_distribution_param(args,model,train_dataset[:TimeseriesData.length],channel_idx)\n",
    "    means.append(mean), covs.append(cov)\n",
    "model_dictionary = {'epoch': max(epoch,start_epoch),\n",
    "                    'best_loss': best_val_loss,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'args': args,\n",
    "                    'means': means,\n",
    "                    'covs': covs\n",
    "                    }\n",
    "model.save_checkpoint(model_dictionary, True)\n",
    "print('-' * 89)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_dataset.size"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nyc_taxi_raw_path = 'nyc_taxi.csv'\n",
    "labeled_data = []\n",
    "with open(str(nyc_taxi_raw_path),'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        tokens = [float(token) for token in line.strip().split(',')[1:]]\n",
    "        tokens.append(1) if 150 < i < 250 or   \\\n",
    "                            5970 < i < 6050 or \\\n",
    "                            8500 < i < 8650 or \\\n",
    "                            8750 < i < 8890 or \\\n",
    "                            10000 < i < 10200 or \\\n",
    "                            14700 < i < 14800 \\\n",
    "                          else tokens.append(0)\n",
    "        labeled_data.append(tokens)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labeled_data[0:100]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.read_csv('../nyc_taxi.csv').columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
