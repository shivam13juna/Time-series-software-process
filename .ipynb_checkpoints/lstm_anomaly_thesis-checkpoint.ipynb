{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/lib/python3.5/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# encoding: utf-8\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from numpy import array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth=True\n",
    "# sess = tf.Session(config=config)\n",
    "# K.set_session(sess)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement=True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "from tensorflow.nn.rnn_cell import LSTMStateTuple\n",
    "\n",
    "from scipy.io import loadmat, savemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "into = loadmat('bidmc_data.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60001, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "into['data']['ppg'][0][0]['v'][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60001, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "into['data']['ppg'][0][0]['v'][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix + 500 > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat1 = into['data']['ppg'][0][0]['v'][0][0].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 15\n",
    "x, y= split_sequence(pat1, n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "x = x.reshape((x.shape[0], x.shape[1], n_features))\n",
    "x = np.array(x, dtype = float)\n",
    "y = np.array(y.reshape((-1, 1)), dtype = float)\n",
    "# Y = Y.reshape((Y.shape[0], Y.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, testx, trainy, testy = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Construction of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "no_units = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.placeholder(dtype=tf.float32, shape=[None, 15, 1])\n",
    "target = tf.placeholder(dtype = tf.float32, shape = [None, 1])\n",
    "batch_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train, target)).batch(batch_size).repeat()\n",
    "test_dataset = tf.data.Dataset.from_tensors((train, target)).repeat()\n",
    "iterr = tf.data.Iterator.from_structure(dataset.output_types, dataset.output_shapes)\n",
    "inputt, outputt = iterr.get_next()\n",
    "\n",
    "#Creating Initialization operations\n",
    "train_init_op = iterr.make_initializer(dataset)\n",
    "test_init_op = iterr.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = math.ceil(trainx.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Encoder Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_fw = [tf.nn.rnn_cell.LSTMCell(num_units = no_units, initializer=tf.keras.initializers.glorot_normal(), state_is_tuple=True)]\n",
    "lstm_bw = [tf.nn.rnn_cell.LSTMCell(num_units = no_units, initializer=tf.keras.initializers.glorot_normal(), state_is_tuple=True)]\n",
    "\n",
    "for i in range(2):\n",
    "    lstm_fw.append(tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.LSTMCell(num_units=no_units, initializer=tf.keras.initializers.glorot_normal(), state_is_tuple=True)]))\n",
    "    lstm_bw.append(tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.LSTMCell(num_units=no_units, initializer=tf.keras.initializers.glorot_normal(), state_is_tuple=True)]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs, encoder_fw_state, encoder_bw_state = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\n",
    "                                                    cells_fw=lstm_fw,\n",
    "                                                    cells_bw = lstm_bw,\n",
    "                                                    inputs = inputt,\n",
    "                                                    dtype = tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_state_c = tf.concat((encoder_fw_state[-1][0].c, encoder_bw_state[-1][0].c), 1)\n",
    "\n",
    "encoder_state_h = tf.concat((encoder_fw_state[-1][0].h, encoder_bw_state[-1][0].h), 1)\n",
    "\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=encoder_state_c,\n",
    "    h=encoder_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.layers.Dense(1)(encoder_state_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(outputt, output)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('tmp'):\n",
    "    os.makedirs('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch going on is... 0 and current loss is... 0.020006267\n",
      "Current epoch going on is... 1 and current loss is... 0.0071088513\n",
      "Current epoch going on is... 2 and current loss is... 0.0035191334\n",
      "Current epoch going on is... 3 and current loss is... 0.0030232708\n",
      "Current epoch going on is... 4 and current loss is... 0.0023893309\n",
      "Current epoch going on is... 5 and current loss is... 0.0021944155\n",
      "Current epoch going on is... 6 and current loss is... 0.002025944\n",
      "Current epoch going on is... 7 and current loss is... 0.0019718453\n",
      "Current epoch going on is... 8 and current loss is... 0.0019187421\n",
      "Current epoch going on is... 9 and current loss is... 0.0018771727\n",
      "Model saved in path: tmp/model_tensorflow.ckpt\n",
      "Now commencing, testing\n",
      "Test loss: 0.001900\n"
     ]
    }
   ],
   "source": [
    "losx = []\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    if(tf.train.checkpoint_exists('tmp/model_tensorflow.ckpt')):\n",
    "        saver.restore(sess, 'tmp/model_tensorflow.ckpt')\n",
    "        print(\"Model Restored\")\n",
    "#     sess.run(iter.initializer, feed_dict={train: x, target: y})\n",
    "    sess.run(train_init_op, feed_dict={train: trainx, target: trainy})\n",
    "    for i in range(epochs):\n",
    "        for _ in range(n_batches):\n",
    "                lossx, idk = sess.run([loss, train_op])\n",
    "                losx.append([loss])                   \n",
    "        print(\"Current epoch going on is...\",i,\"and current loss is...\", lossx)\n",
    "    save_path = saver.save(sess, 'tmp/model_tensorflow.ckpt')\n",
    "    print(\"Model saved in path: %s\"%save_path)\n",
    "    \n",
    "    print(\"Now commencing, testing\")\n",
    "    sess.run(test_init_op, feed_dict = {train:testx, target:testy})\n",
    "    print(\"Test loss: {:4f}\".format(sess.run(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/model_tensorflow.ckpt\n",
      "Model Restored\n",
      "Test loss: 0.001900\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    if(tf.train.checkpoint_exists('tmp/model_tensorflow.ckpt')):\n",
    "        saver.restore(sess, 'tmp/model_tensorflow.ckpt')\n",
    "        print(\"Model Restored\")\n",
    "#     sess.run(iter.initializer, feed_dict={train: x, target: y})\n",
    "    sess.run(test_init_op, feed_dict = {train:testx, target:testy})\n",
    "    print(\"Test loss: {:4f}\".format(sess.run(loss)))\n",
    "    prediction = sess.run(output).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14872,)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
