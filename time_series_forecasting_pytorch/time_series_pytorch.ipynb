{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from generate_data import *\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#####################\n",
    "# Set parameters\n",
    "#####################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = ['vnf label', 'vnf min cpu', 'vnf min mem', 'vnf min sto', 'vnf vm cpu',\n",
    "       'vnf vm mem', 'vnf vm sto', 'vnf pm id', 'vnf cpu usage',\n",
    "       'vnf mem usage', 'vnf sto usage', 'vnf before', 'vnf after',\n",
    "       'vnf label.1', 'vnf min cpu.1', 'vnf min mem.1', 'vnf min sto.1',\n",
    "       'vnf vm cpu.1', 'vnf vm mem.1', 'vnf vm sto.1', 'vnf pm id.1',\n",
    "       'vnf cpu usage.1', 'vnf mem usage.1', 'vnf sto usage.1', 'vnf before.1',\n",
    "       'vnf after.1', 'sla', 'fg id', 'flow traffic', 'flow latency',\n",
    "       'flow bnd usage', 'flow packet loss', 'min cpu affinity',\n",
    "       'min mem affinity', 'min sto affinity', 'conflicts affinity',\n",
    "       'real_affinity', 'static_affinity', 'predicted_affinity',\n",
    "       'prediction_time', 'TF', 'MTT', 'MTT_upper', 'MTT_lower', 'MTTF_R',\n",
    "       'MTTF_EM', 'MTTF_C', 'MTTF_TDDB', 'MTTF_SM', 'MTTFF_TC', 'A', 'AEM',\n",
    "       'AC', 'ATDDB', 'ASM', 'ATC', 'TAA', 'QRED', 'QR', 'PUE', 'DCie', 'cost',\n",
    "       'TIMESTAMP', 'EXTERNAL_TEMP', 'ROOM_TEMP', 'MTTF_IC', 'A_TC', 'Q_DIT',\n",
    "       'TPF', 'AIRFLOW', 'TAAF', 'DeltaT_de', 'QD']\n",
    "       \n",
    "       \n",
    "#Select your global variable among one of above, and place it after base below\n",
    "\n",
    "\n",
    "base = 'vnf cpu usage'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs = pd.read_csv('../fgs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>4963594775</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>proxy.9.5698</th>\n",
       "      <th>traffic counter.7.5664</th>\n",
       "      <th>0.971442</th>\n",
       "      <th>82.243099</th>\n",
       "      <td>1.794354</td>\n",
       "      <td>9.341767</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402488769</th>\n",
       "      <th>5</th>\n",
       "      <th>1.000000</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traffic counter.7.7413</th>\n",
       "      <th>proxy.9.11244</th>\n",
       "      <th>4.060322</th>\n",
       "      <th>119.086081</th>\n",
       "      <td>16.548350</td>\n",
       "      <td>8.474562</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proxy.9.11244</th>\n",
       "      <th>proxy.9.2362</th>\n",
       "      <th>0.268318</th>\n",
       "      <th>23.865256</th>\n",
       "      <td>11.573841</td>\n",
       "      <td>9.248256</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proxy.9.2362</th>\n",
       "      <th>traffic counter.7.9524</th>\n",
       "      <th>2.961259</th>\n",
       "      <th>80.083566</th>\n",
       "      <td>18.280812</td>\n",
       "      <td>4.783467</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   4963594775  \\\n",
       "proxy.9.5698           traffic counter.7.5664 0.971442 82.243099     1.794354   \n",
       "5402488769             5                      1.000000 NaN                NaN   \n",
       "traffic counter.7.7413 proxy.9.11244          4.060322 119.086081   16.548350   \n",
       "proxy.9.11244          proxy.9.2362           0.268318 23.865256    11.573841   \n",
       "proxy.9.2362           traffic counter.7.9524 2.961259 80.083566    18.280812   \n",
       "\n",
       "                                                                          1  \\\n",
       "proxy.9.5698           traffic counter.7.5664 0.971442 82.243099   9.341767   \n",
       "5402488769             5                      1.000000 NaN              NaN   \n",
       "traffic counter.7.7413 proxy.9.11244          4.060322 119.086081  8.474562   \n",
       "proxy.9.11244          proxy.9.2362           0.268318 23.865256   9.248256   \n",
       "proxy.9.2362           traffic counter.7.9524 2.961259 80.083566   4.783467   \n",
       "\n",
       "                                                                       2  \n",
       "proxy.9.5698           traffic counter.7.5664 0.971442 82.243099   100.0  \n",
       "5402488769             5                      1.000000 NaN           NaN  \n",
       "traffic counter.7.7413 proxy.9.11244          4.060322 119.086081  150.0  \n",
       "proxy.9.11244          proxy.9.2362           0.268318 23.865256   150.0  \n",
       "proxy.9.2362           traffic counter.7.9524 2.961259 80.083566   150.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vns = pd.read_csv('../vnfs.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just separating our input dataset, for better understanding of dataset\n",
    "vnf_id = np.array(vns[vns.columns[0]])\n",
    "vnf_type = np.array(vns[vns.columns[1]])\n",
    "vnf_scheduling = np.array(vns[vns.columns[2]])\n",
    "vnf_pm = np.array(vns[vns.columns[3]])\n",
    "vnf_fg = np.array(vns[vns.columns[4]])\n",
    "flavor_data = np.array(vns[vns.columns[5:8]])\n",
    "vm_data = np.array(vns[vns.columns[8:11]])\n",
    "usage_data = np.array(vns[vns.columns[11:15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12322, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv('../new_results_out.csv', sep =';')# Reading target dataset\n",
    "output.drop('Unnamed: 0',axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vnf label</th>\n",
       "      <th>vnf min cpu</th>\n",
       "      <th>vnf min mem</th>\n",
       "      <th>vnf min sto</th>\n",
       "      <th>vnf vm cpu</th>\n",
       "      <th>vnf vm mem</th>\n",
       "      <th>vnf vm sto</th>\n",
       "      <th>vnf pm id</th>\n",
       "      <th>vnf cpu usage</th>\n",
       "      <th>vnf mem usage</th>\n",
       "      <th>...</th>\n",
       "      <th>EXTERNAL_TEMP</th>\n",
       "      <th>ROOM_TEMP</th>\n",
       "      <th>MTTF_IC</th>\n",
       "      <th>A_TC</th>\n",
       "      <th>Q_DIT</th>\n",
       "      <th>TPF</th>\n",
       "      <th>AIRFLOW</th>\n",
       "      <th>TAAF</th>\n",
       "      <th>DeltaT_de</th>\n",
       "      <th>QD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dpi.2.136144</td>\n",
       "      <td>0.035914</td>\n",
       "      <td>0.226393</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.12720</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>257345416</td>\n",
       "      <td>71.88000</td>\n",
       "      <td>1.75780</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>2435.249666</td>\n",
       "      <td>0.996726</td>\n",
       "      <td>1.839678</td>\n",
       "      <td>14.999377</td>\n",
       "      <td>0.131858</td>\n",
       "      <td>0.872117</td>\n",
       "      <td>6.132259</td>\n",
       "      <td>6.132259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traffic counter.7.40368</td>\n",
       "      <td>0.063818</td>\n",
       "      <td>0.017674</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.06189</td>\n",
       "      <td>0.03821</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>3488796635</td>\n",
       "      <td>3.51600</td>\n",
       "      <td>6.34800</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>49.077683</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>1.801941</td>\n",
       "      <td>14.999402</td>\n",
       "      <td>0.142946</td>\n",
       "      <td>0.768427</td>\n",
       "      <td>6.006469</td>\n",
       "      <td>6.006469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proxy.9.13456</td>\n",
       "      <td>0.018672</td>\n",
       "      <td>0.020912</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.01250</td>\n",
       "      <td>0.01590</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>4820294844</td>\n",
       "      <td>0.18044</td>\n",
       "      <td>0.13352</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>82.372536</td>\n",
       "      <td>0.911478</td>\n",
       "      <td>1.800100</td>\n",
       "      <td>54.999420</td>\n",
       "      <td>0.152569</td>\n",
       "      <td>0.757640</td>\n",
       "      <td>6.000332</td>\n",
       "      <td>6.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firewall.3.36933</td>\n",
       "      <td>0.140469</td>\n",
       "      <td>0.021706</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.03198</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>3550430599</td>\n",
       "      <td>26.46000</td>\n",
       "      <td>6.44600</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>0.044220</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>1.814606</td>\n",
       "      <td>39.999481</td>\n",
       "      <td>0.132889</td>\n",
       "      <td>0.807089</td>\n",
       "      <td>6.048686</td>\n",
       "      <td>6.048686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dpi.2.92594</td>\n",
       "      <td>0.015708</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.08569</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>4820072706</td>\n",
       "      <td>41.74000</td>\n",
       "      <td>14.42800</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>1.823040</td>\n",
       "      <td>20.999427</td>\n",
       "      <td>0.189031</td>\n",
       "      <td>0.790021</td>\n",
       "      <td>6.076802</td>\n",
       "      <td>6.076802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 vnf label  vnf min cpu  vnf min mem  vnf min sto  vnf vm cpu  \\\n",
       "0             dpi.2.136144     0.035914     0.226393     0.001757     0.06250   \n",
       "1  traffic counter.7.40368     0.063818     0.017674     0.000223     0.06189   \n",
       "2            proxy.9.13456     0.018672     0.020912     0.000006     0.01250   \n",
       "3         firewall.3.36933     0.140469     0.021706     0.000068     0.09375   \n",
       "4              dpi.2.92594     0.015708     0.050654     0.000810     0.06250   \n",
       "\n",
       "   vnf vm mem  vnf vm sto   vnf pm id  vnf cpu usage  vnf mem usage  ...  \\\n",
       "0     0.12720    0.001930   257345416       71.88000        1.75780  ...   \n",
       "1     0.03821    0.000386  3488796635        3.51600        6.34800  ...   \n",
       "2     0.01590    0.000404  4820294844        0.18044        0.13352  ...   \n",
       "3     0.03198    0.000070  3550430599       26.46000        6.44600  ...   \n",
       "4     0.08569    0.000926  4820072706       41.74000       14.42800  ...   \n",
       "\n",
       "   EXTERNAL_TEMP ROOM_TEMP      MTTF_IC      A_TC     Q_DIT        TPF  \\\n",
       "0             15        23  2435.249666  0.996726  1.839678  14.999377   \n",
       "1             15        24    49.077683  0.859840  1.801941  14.999402   \n",
       "2             55        25    82.372536  0.911478  1.800100  54.999420   \n",
       "3             40        23     0.044220  0.005497  1.814606  39.999481   \n",
       "4             21        29     0.011200  0.001398  1.823040  20.999427   \n",
       "\n",
       "    AIRFLOW      TAAF  DeltaT_de        QD  \n",
       "0  0.131858  0.872117   6.132259  6.132259  \n",
       "1  0.142946  0.768427   6.006469  6.006469  \n",
       "2  0.152569  0.757640   6.000332  6.000332  \n",
       "3  0.132889  0.807089   6.048686  6.048686  \n",
       "4  0.189031  0.790021   6.076802  6.076802  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vnf label', 'vnf min cpu', 'vnf min mem', 'vnf min sto', 'vnf vm cpu',\n",
       "       'vnf vm mem', 'vnf vm sto', 'vnf pm id', 'vnf cpu usage',\n",
       "       'vnf mem usage', 'vnf sto usage', 'vnf before', 'vnf after',\n",
       "       'vnf label.1', 'vnf min cpu.1', 'vnf min mem.1', 'vnf min sto.1',\n",
       "       'vnf vm cpu.1', 'vnf vm mem.1', 'vnf vm sto.1', 'vnf pm id.1',\n",
       "       'vnf cpu usage.1', 'vnf mem usage.1', 'vnf sto usage.1', 'vnf before.1',\n",
       "       'vnf after.1', 'sla', 'fg id', 'flow traffic', 'flow latency',\n",
       "       'flow bnd usage', 'flow packet loss', 'min cpu affinity',\n",
       "       'min mem affinity', 'min sto affinity', 'conflicts affinity',\n",
       "       'real_affinity', 'static_affinity', 'predicted_affinity',\n",
       "       'prediction_time', 'TF', 'MTT', 'MTT_upper', 'MTT_lower', 'MTTF_R',\n",
       "       'MTTF_EM', 'MTTF_C', 'MTTF_TDDB', 'MTTF_SM', 'MTTFF_TC', 'A', 'AEM',\n",
       "       'AC', 'ATDDB', 'ASM', 'ATC', 'TAA', 'QRED', 'QR', 'PUE', 'DCie', 'cost',\n",
       "       'TIMESTAMP', 'EXTERNAL_TEMP', 'ROOM_TEMP', 'MTTF_IC', 'A_TC', 'Q_DIT',\n",
       "       'TPF', 'AIRFLOW', 'TAAF', 'DeltaT_de', 'QD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195379,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['vnf cpu usage'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output[:12322] #Doing this as we discussed, our input datset has only 12322 records\n",
    "output = output[base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12322,)\n",
      "(12322,)\n",
      "(12322,)\n",
      "(12322,)\n",
      "(12322,)\n",
      "(12322, 3)\n",
      "(12322, 3)\n",
      "(12322, 4)\n"
     ]
    }
   ],
   "source": [
    "thelist = [vnf_id, vnf_type, vnf_scheduling, vnf_pm, vnf_fg, flavor_data, vm_data, usage_data] #Just pre-processing with input\n",
    "for i in range(len(thelist)):\n",
    "    print(thelist[i].shape)\n",
    "    if len(thelist[i].shape) == 1:\n",
    "        thelist[i] = np.reshape(thelist[i], (-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnf_id = np.reshape(vnf_id, (-1, 1))\n",
    "vnf_type = np.reshape(vnf_type, (-1, 1))\n",
    "vnf_scheduling = np.reshape(vnf_scheduling, (-1, 1))\n",
    "vnf_pm = np.reshape(vnf_pm, (-1, 1))\n",
    "vnf_fg = np.reshape(vnf_fg, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12322, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnf_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputt = np.concatenate((vnf_id, vnf_type, vnf_scheduling, vnf_pm, vnf_fg, flavor_data, vm_data, usage_data), axis=1) #concatenating them again, for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max = MinMaxScaler()\n",
    "inputt_scaled = min_max.fit_transform(inputt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12322, 15)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, testx, trainy, testy = train_test_split(inputt, output, test_size=0.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainx shape (10104, 15)\n",
      "Trainy shape (10104,)\n",
      "Testx shape (2218, 15)\n",
      "Testy shape (2218,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainx shape\", trainx.shape)\n",
    "print(\"Trainy shape\", trainy.shape)\n",
    "print(\"Testx shape\", testx.shape)\n",
    "print(\"Testy shape\", testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = trainx[:10100]\n",
    "trainy = trainy[:10100]\n",
    "testx = testx[:2210]\n",
    "testy = testy[:2210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.gcd(10100, 2210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = np.array(trainx)\n",
    "trainy = np.array(trainy)\n",
    "testx = np.array(testx)\n",
    "testy = np.array(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping data for LSTM\n",
    "\n",
    "trainx = trainx.reshape((-1, 10, 15)) #Dividing them as it should be as per the shape of LSTM, batch_size, timtsteps, features\n",
    "trainy = trainy.reshape((-1, 10))\n",
    "testx = testx.reshape((-1, 10, 15))\n",
    "testy = testy.reshape((-1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010, 10, 15)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data params\n",
    "noise_var = 0\n",
    "num_datapoints = 100\n",
    "test_size = 0.2\n",
    "num_train = int((1-test_size) * num_datapoints)\n",
    "\n",
    "# Network params\n",
    "\n",
    "# size of hidden layers\n",
    "h1 = 32\n",
    "output_dim = 10\n",
    "num_layers = 2\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 500\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size of one instance from iter is:  torch.Size([100, 10, 15])\n",
      "Sample target size of that same one instance from iter is torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "#Creating Tensor Datasets\n",
    "train_data = TensorDataset(torch.from_numpy(trainx).double(), torch.from_numpy(trainy).float())\n",
    "test_data = TensorDataset(torch.from_numpy(testx).double(), torch.from_numpy(testy).float())\n",
    "\n",
    "#Now creating Data Loaders\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle = True, batch_size = batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle = True, batch_size = batch_size)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print(\"Sample input size of one instance from iter is: \", sample_x.size()) #Batch size, Sequence Length, Feature Dimension\n",
    "print(\"Sample target size of that same one instance from iter is\", sample_y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bonhwa_lstm(nn.Module):\n",
    "    def __init__(self, embedding_dim, no_units, output_dim, n_layers):\n",
    "        super(bonhwa_lstm, self).__init__()\n",
    "        self.no_units = no_units\n",
    "        self.n_layers = n_layers\n",
    "        self.lstm = nn.LSTM(embedding_dim, no_units, n_layers, batch_first = True, bidirectional = True)\n",
    "        self.linear = nn.Linear(no_units * 2, output_dim)\n",
    "#         self.soft = nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        hidden = self.init_hidden(x.size(0))\n",
    "        lstmout, hidden = self.lstm(x.float(), hidden)\n",
    "#         lstmout = lstmout.contiguous().view(-1, self.no_units)\n",
    "\n",
    "        output = self.linear(lstmout)\n",
    "        \n",
    "#         output = self.soft(output)\n",
    "        return output[:, -1, :], hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers * 2, batch_size, self.no_units).zero_().cuda(),\n",
    "                      weight.new(self.n_layers * 2, batch_size, self.no_units).zero_().cuda())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = bonhwa_lstm(embedding_dim = 15, output_dim = 10, no_units = 524, n_layers = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000 ... Step: 0... Loss: 520.4373...\n",
      "Epoch: 6/1000 ... Step: 0... Loss: 713.8788...\n",
      "Epoch: 11/1000 ... Step: 0... Loss: 597.9655...\n",
      "Epoch: 16/1000 ... Step: 0... Loss: 568.4521...\n",
      "Epoch: 21/1000 ... Step: 0... Loss: 618.7610...\n",
      "Epoch: 26/1000 ... Step: 0... Loss: 625.2312...\n",
      "Epoch: 31/1000 ... Step: 0... Loss: 635.9028...\n",
      "Epoch: 36/1000 ... Step: 0... Loss: 590.7043...\n",
      "Epoch: 41/1000 ... Step: 0... Loss: 547.3220...\n",
      "Epoch: 46/1000 ... Step: 0... Loss: 530.7495...\n",
      "Epoch: 51/1000 ... Step: 0... Loss: 578.2459...\n",
      "Epoch: 56/1000 ... Step: 0... Loss: 573.8039...\n",
      "Epoch: 61/1000 ... Step: 0... Loss: 579.2821...\n",
      "Epoch: 66/1000 ... Step: 0... Loss: 585.0622...\n",
      "Epoch: 71/1000 ... Step: 0... Loss: 554.2413...\n",
      "Epoch: 76/1000 ... Step: 0... Loss: 539.2403...\n",
      "Epoch: 81/1000 ... Step: 0... Loss: 532.0670...\n",
      "Epoch: 86/1000 ... Step: 0... Loss: 548.3129...\n",
      "Epoch: 91/1000 ... Step: 0... Loss: 600.9075...\n",
      "Epoch: 96/1000 ... Step: 0... Loss: 545.2194...\n",
      "Epoch: 101/1000 ... Step: 0... Loss: 492.7582...\n",
      "Epoch: 106/1000 ... Step: 0... Loss: 588.3361...\n",
      "Epoch: 111/1000 ... Step: 0... Loss: 635.2259...\n",
      "Epoch: 116/1000 ... Step: 0... Loss: 596.4836...\n",
      "Epoch: 121/1000 ... Step: 0... Loss: 565.0012...\n",
      "Epoch: 126/1000 ... Step: 0... Loss: 610.1345...\n",
      "Epoch: 131/1000 ... Step: 0... Loss: 551.8785...\n",
      "Epoch: 136/1000 ... Step: 0... Loss: 636.9296...\n",
      "Epoch: 141/1000 ... Step: 0... Loss: 542.9852...\n",
      "Epoch: 146/1000 ... Step: 0... Loss: 489.1599...\n",
      "Epoch: 151/1000 ... Step: 0... Loss: 448.4147...\n",
      "Epoch: 156/1000 ... Step: 0... Loss: 647.6065...\n",
      "Epoch: 161/1000 ... Step: 0... Loss: 581.6206...\n",
      "Epoch: 166/1000 ... Step: 0... Loss: 574.9033...\n",
      "Epoch: 171/1000 ... Step: 0... Loss: 515.5215...\n",
      "Epoch: 176/1000 ... Step: 0... Loss: 446.8367...\n",
      "Epoch: 181/1000 ... Step: 0... Loss: 636.8095...\n",
      "Epoch: 186/1000 ... Step: 0... Loss: 557.8302...\n",
      "Epoch: 191/1000 ... Step: 0... Loss: 483.3362...\n",
      "Epoch: 196/1000 ... Step: 0... Loss: 535.2073...\n",
      "Epoch: 201/1000 ... Step: 0... Loss: 509.7610...\n",
      "Epoch: 206/1000 ... Step: 0... Loss: 520.5794...\n",
      "Epoch: 211/1000 ... Step: 0... Loss: 518.3747...\n",
      "Epoch: 216/1000 ... Step: 0... Loss: 442.9037...\n",
      "Epoch: 221/1000 ... Step: 0... Loss: 451.5267...\n",
      "Epoch: 226/1000 ... Step: 0... Loss: 464.9974...\n",
      "Epoch: 231/1000 ... Step: 0... Loss: 527.1089...\n",
      "Epoch: 236/1000 ... Step: 0... Loss: 520.3079...\n",
      "Epoch: 241/1000 ... Step: 0... Loss: 473.2537...\n",
      "Epoch: 246/1000 ... Step: 0... Loss: 460.2534...\n",
      "Epoch: 251/1000 ... Step: 0... Loss: 459.4434...\n",
      "Epoch: 256/1000 ... Step: 0... Loss: 461.9816...\n",
      "Epoch: 261/1000 ... Step: 0... Loss: 434.4376...\n",
      "Epoch: 266/1000 ... Step: 0... Loss: 434.8326...\n",
      "Epoch: 271/1000 ... Step: 0... Loss: 432.8463...\n",
      "Epoch: 276/1000 ... Step: 0... Loss: 462.2754...\n",
      "Epoch: 281/1000 ... Step: 0... Loss: 449.4803...\n",
      "Epoch: 286/1000 ... Step: 0... Loss: 511.4601...\n",
      "Epoch: 291/1000 ... Step: 0... Loss: 497.4771...\n",
      "Epoch: 296/1000 ... Step: 0... Loss: 469.3857...\n",
      "Epoch: 301/1000 ... Step: 0... Loss: 551.7822...\n",
      "Epoch: 306/1000 ... Step: 0... Loss: 575.4448...\n",
      "Epoch: 311/1000 ... Step: 0... Loss: 514.2996...\n",
      "Epoch: 316/1000 ... Step: 0... Loss: 418.7445...\n",
      "Epoch: 321/1000 ... Step: 0... Loss: 489.3783...\n",
      "Epoch: 326/1000 ... Step: 0... Loss: 489.7377...\n",
      "Epoch: 331/1000 ... Step: 0... Loss: 503.0734...\n",
      "Epoch: 336/1000 ... Step: 0... Loss: 445.7756...\n",
      "Epoch: 341/1000 ... Step: 0... Loss: 490.0049...\n",
      "Epoch: 346/1000 ... Step: 0... Loss: 426.9272...\n",
      "Epoch: 351/1000 ... Step: 0... Loss: 468.0466...\n",
      "Epoch: 356/1000 ... Step: 0... Loss: 405.6787...\n",
      "Epoch: 361/1000 ... Step: 0... Loss: 448.2697...\n",
      "Epoch: 366/1000 ... Step: 0... Loss: 430.4836...\n",
      "Epoch: 371/1000 ... Step: 0... Loss: 423.3327...\n",
      "Epoch: 376/1000 ... Step: 0... Loss: 460.8337...\n",
      "Epoch: 381/1000 ... Step: 0... Loss: 496.1145...\n",
      "Epoch: 386/1000 ... Step: 0... Loss: 458.9752...\n",
      "Epoch: 391/1000 ... Step: 0... Loss: 458.3821...\n",
      "Epoch: 396/1000 ... Step: 0... Loss: 495.7265...\n",
      "Epoch: 401/1000 ... Step: 0... Loss: 448.9129...\n",
      "Epoch: 406/1000 ... Step: 0... Loss: 441.7793...\n",
      "Epoch: 411/1000 ... Step: 0... Loss: 442.8192...\n",
      "Epoch: 416/1000 ... Step: 0... Loss: 411.9188...\n",
      "Epoch: 421/1000 ... Step: 0... Loss: 396.5240...\n",
      "Epoch: 426/1000 ... Step: 0... Loss: 450.4147...\n",
      "Epoch: 431/1000 ... Step: 0... Loss: 448.4729...\n",
      "Epoch: 436/1000 ... Step: 0... Loss: 404.8210...\n",
      "Epoch: 441/1000 ... Step: 0... Loss: 417.6821...\n",
      "Epoch: 446/1000 ... Step: 0... Loss: 437.4593...\n",
      "Epoch: 451/1000 ... Step: 0... Loss: 535.8486...\n",
      "Epoch: 456/1000 ... Step: 0... Loss: 435.2001...\n",
      "Epoch: 461/1000 ... Step: 0... Loss: 447.2878...\n",
      "Epoch: 466/1000 ... Step: 0... Loss: 482.2463...\n",
      "Epoch: 471/1000 ... Step: 0... Loss: 386.7542...\n",
      "Epoch: 476/1000 ... Step: 0... Loss: 416.8275...\n",
      "Epoch: 481/1000 ... Step: 0... Loss: 495.9210...\n",
      "Epoch: 486/1000 ... Step: 0... Loss: 449.4855...\n",
      "Epoch: 491/1000 ... Step: 0... Loss: 393.8938...\n",
      "Epoch: 496/1000 ... Step: 0... Loss: 415.6479...\n",
      "Epoch: 501/1000 ... Step: 0... Loss: 450.8830...\n",
      "Epoch: 506/1000 ... Step: 0... Loss: 422.4180...\n",
      "Epoch: 511/1000 ... Step: 0... Loss: 406.0875...\n",
      "Epoch: 516/1000 ... Step: 0... Loss: 383.1268...\n",
      "Epoch: 521/1000 ... Step: 0... Loss: 446.0886...\n",
      "Epoch: 526/1000 ... Step: 0... Loss: 440.3840...\n",
      "Epoch: 531/1000 ... Step: 0... Loss: 435.9999...\n",
      "Epoch: 536/1000 ... Step: 0... Loss: 445.6324...\n",
      "Epoch: 541/1000 ... Step: 0... Loss: 375.7978...\n",
      "Epoch: 546/1000 ... Step: 0... Loss: 366.9810...\n",
      "Epoch: 551/1000 ... Step: 0... Loss: 390.3323...\n",
      "Epoch: 556/1000 ... Step: 0... Loss: 421.4235...\n",
      "Epoch: 561/1000 ... Step: 0... Loss: 395.8064...\n",
      "Epoch: 566/1000 ... Step: 0... Loss: 437.9157...\n",
      "Epoch: 571/1000 ... Step: 0... Loss: 376.2406...\n",
      "Epoch: 576/1000 ... Step: 0... Loss: 391.4263...\n",
      "Epoch: 581/1000 ... Step: 0... Loss: 427.6096...\n",
      "Epoch: 586/1000 ... Step: 0... Loss: 371.1956...\n",
      "Epoch: 591/1000 ... Step: 0... Loss: 422.5706...\n",
      "Epoch: 596/1000 ... Step: 0... Loss: 367.8438...\n",
      "Epoch: 601/1000 ... Step: 0... Loss: 455.8849...\n",
      "Epoch: 606/1000 ... Step: 0... Loss: 397.6805...\n",
      "Epoch: 611/1000 ... Step: 0... Loss: 418.0580...\n",
      "Epoch: 616/1000 ... Step: 0... Loss: 410.2328...\n",
      "Epoch: 621/1000 ... Step: 0... Loss: 396.8785...\n",
      "Epoch: 626/1000 ... Step: 0... Loss: 438.3154...\n",
      "Epoch: 631/1000 ... Step: 0... Loss: 360.7719...\n",
      "Epoch: 636/1000 ... Step: 0... Loss: 333.1340...\n",
      "Epoch: 641/1000 ... Step: 0... Loss: 367.2574...\n",
      "Epoch: 646/1000 ... Step: 0... Loss: 360.3618...\n",
      "Epoch: 651/1000 ... Step: 0... Loss: 418.2037...\n",
      "Epoch: 656/1000 ... Step: 0... Loss: 347.4295...\n",
      "Epoch: 661/1000 ... Step: 0... Loss: 365.9134...\n",
      "Epoch: 666/1000 ... Step: 0... Loss: 378.2649...\n",
      "Epoch: 671/1000 ... Step: 0... Loss: 379.2010...\n",
      "Epoch: 676/1000 ... Step: 0... Loss: 396.2651...\n",
      "Epoch: 681/1000 ... Step: 0... Loss: 406.5799...\n",
      "Epoch: 686/1000 ... Step: 0... Loss: 380.0853...\n",
      "Epoch: 691/1000 ... Step: 0... Loss: 440.5091...\n",
      "Epoch: 696/1000 ... Step: 0... Loss: 351.4188...\n",
      "Epoch: 701/1000 ... Step: 0... Loss: 430.4448...\n",
      "Epoch: 706/1000 ... Step: 0... Loss: 375.6281...\n",
      "Epoch: 711/1000 ... Step: 0... Loss: 387.8817...\n",
      "Epoch: 716/1000 ... Step: 0... Loss: 368.9167...\n",
      "Epoch: 721/1000 ... Step: 0... Loss: 410.1217...\n",
      "Epoch: 726/1000 ... Step: 0... Loss: 375.9312...\n",
      "Epoch: 731/1000 ... Step: 0... Loss: 345.4197...\n",
      "Epoch: 736/1000 ... Step: 0... Loss: 390.6888...\n",
      "Epoch: 741/1000 ... Step: 0... Loss: 369.1880...\n",
      "Epoch: 746/1000 ... Step: 0... Loss: 375.1786...\n",
      "Epoch: 751/1000 ... Step: 0... Loss: 397.2570...\n",
      "Epoch: 756/1000 ... Step: 0... Loss: 360.3972...\n",
      "Epoch: 761/1000 ... Step: 0... Loss: 360.0110...\n",
      "Epoch: 766/1000 ... Step: 0... Loss: 329.9838...\n",
      "Epoch: 771/1000 ... Step: 0... Loss: 315.4839...\n",
      "Epoch: 776/1000 ... Step: 0... Loss: 457.5995...\n",
      "Epoch: 781/1000 ... Step: 0... Loss: 373.8431...\n",
      "Epoch: 786/1000 ... Step: 0... Loss: 398.7107...\n",
      "Epoch: 791/1000 ... Step: 0... Loss: 321.8803...\n",
      "Epoch: 796/1000 ... Step: 0... Loss: 346.3917...\n",
      "Epoch: 801/1000 ... Step: 0... Loss: 334.1004...\n",
      "Epoch: 806/1000 ... Step: 0... Loss: 360.8029...\n",
      "Epoch: 811/1000 ... Step: 0... Loss: 324.4929...\n",
      "Epoch: 816/1000 ... Step: 0... Loss: 372.1097...\n",
      "Epoch: 821/1000 ... Step: 0... Loss: 360.5481...\n",
      "Epoch: 826/1000 ... Step: 0... Loss: 441.9261...\n",
      "Epoch: 831/1000 ... Step: 0... Loss: 409.1337...\n",
      "Epoch: 836/1000 ... Step: 0... Loss: 377.5667...\n",
      "Epoch: 841/1000 ... Step: 0... Loss: 373.7497...\n",
      "Epoch: 846/1000 ... Step: 0... Loss: 346.4708...\n",
      "Epoch: 851/1000 ... Step: 0... Loss: 336.9244...\n",
      "Epoch: 856/1000 ... Step: 0... Loss: 403.4397...\n",
      "Epoch: 861/1000 ... Step: 0... Loss: 298.5053...\n",
      "Epoch: 866/1000 ... Step: 0... Loss: 430.6205...\n",
      "Epoch: 871/1000 ... Step: 0... Loss: 367.7935...\n",
      "Epoch: 876/1000 ... Step: 0... Loss: 365.2480...\n",
      "Epoch: 881/1000 ... Step: 0... Loss: 341.9632...\n",
      "Epoch: 886/1000 ... Step: 0... Loss: 319.0906...\n",
      "Epoch: 891/1000 ... Step: 0... Loss: 356.4653...\n",
      "Epoch: 896/1000 ... Step: 0... Loss: 350.1951...\n",
      "Epoch: 901/1000 ... Step: 0... Loss: 336.0174...\n",
      "Epoch: 906/1000 ... Step: 0... Loss: 300.1838...\n",
      "Epoch: 911/1000 ... Step: 0... Loss: 315.5709...\n",
      "Epoch: 916/1000 ... Step: 0... Loss: 378.6292...\n",
      "Epoch: 921/1000 ... Step: 0... Loss: 349.4060...\n",
      "Epoch: 926/1000 ... Step: 0... Loss: 401.8178...\n",
      "Epoch: 931/1000 ... Step: 0... Loss: 337.0576...\n",
      "Epoch: 936/1000 ... Step: 0... Loss: 335.7495...\n",
      "Epoch: 941/1000 ... Step: 0... Loss: 368.0661...\n",
      "Epoch: 946/1000 ... Step: 0... Loss: 341.9294...\n",
      "Epoch: 951/1000 ... Step: 0... Loss: 409.5641...\n",
      "Epoch: 956/1000 ... Step: 0... Loss: 298.4195...\n",
      "Epoch: 961/1000 ... Step: 0... Loss: 319.3893...\n",
      "Epoch: 966/1000 ... Step: 0... Loss: 283.5184...\n",
      "Epoch: 971/1000 ... Step: 0... Loss: 299.6848...\n",
      "Epoch: 976/1000 ... Step: 0... Loss: 314.8348...\n",
      "Epoch: 981/1000 ... Step: 0... Loss: 349.4991...\n",
      "Epoch: 986/1000 ... Step: 0... Loss: 339.8910...\n",
      "Epoch: 991/1000 ... Step: 0... Loss: 318.3404...\n",
      "Epoch: 996/1000 ... Step: 0... Loss: 309.7975...\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "# net.float()\n",
    "net.cuda()\n",
    "criterion = torch.nn.L1Loss(size_average=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 1000\n",
    "counter = 0\n",
    "clip = 5\n",
    "tr_ac = []\n",
    "val_losses = []\n",
    "vl_actr_ac = []\n",
    "val_losses = []\n",
    "vl_ac = []\n",
    "ee = -1\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    #Initializing hidden state\n",
    "    hd = net.init_hidden(batch_size)\n",
    "    for batch_i, target_i in train_loader:\n",
    "\n",
    "\n",
    "\n",
    "        inputs, targets = batch_i.cuda(), target_i.cuda()\n",
    "\n",
    "        hd = tuple([each.data for each in hd])\n",
    "\n",
    "        net.zero_grad()\n",
    "\n",
    "        outputs, hd = net(inputs, hd)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            net.eval()\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            \n",
    "\n",
    "            for batch_j, target_j in test_loader:\n",
    "\n",
    "                vinputs, vtargets = batch_j.cuda(), target_j.cuda()\n",
    "\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                output_h, val_h = net(vinputs, val_h)\n",
    "                val_loss = criterion(output_h, vtargets)\n",
    "                val_losses.append(val_loss.item())\n",
    "            if ee != i:\n",
    "                ee = i \n",
    "                print(\"Epoch: {}/{} ...\".format(i+1, epochs),\n",
    "              \"Step: {}...\".format(counter),\n",
    "              \"Loss: {:.4f}...\".format(loss.item()))\n",
    "\n",
    "        net.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name= 'Bonhwa.pt'\n",
    "torch.save(net.state_dict(),model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_model =  bonhwa_lstm(embedding_dim = 15, output_dim = 10, no_units = 524, n_layers = 2)\n",
    "the_model = torch.load('Bonhwa.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([21, 10])\n"
     ]
    }
   ],
   "source": [
    "for batch_j, target_j in test_loader:\n",
    "\n",
    "            vinputs, vtargets = batch_j.cuda(), target_j.cuda()\n",
    "\n",
    "            val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "            output_h, val_h = net(vinputs, val_h)\n",
    "            loss = criterion(output_h, vtargets)\n",
    "            print(output_h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, which is L1 loss, scaled as per batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.61708837890625"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.cpu().detach().numpy()/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_h = output_h.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_h[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feb65392128>]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(testy[-1])\n",
    "plt.plot(output_h[-1]) #Plotting for 10 random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
