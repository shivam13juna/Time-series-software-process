{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding: utf-8\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from numpy import array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth=True\n",
    "# sess = tf.Session(config=config)\n",
    "# K.set_session(sess)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement=True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "from tensorflow.nn.rnn_cell import LSTMStateTuple\n",
    "\n",
    "from scipy.io import loadmat, savemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = ['vnf label', 'vnf min cpu', 'vnf min mem', 'vnf min sto', 'vnf vm cpu',\n",
    "       'vnf vm mem', 'vnf vm sto', 'vnf pm id', 'vnf cpu usage',\n",
    "       'vnf mem usage', 'vnf sto usage', 'vnf before', 'vnf after',\n",
    "       'vnf label.1', 'vnf min cpu.1', 'vnf min mem.1', 'vnf min sto.1',\n",
    "       'vnf vm cpu.1', 'vnf vm mem.1', 'vnf vm sto.1', 'vnf pm id.1',\n",
    "       'vnf cpu usage.1', 'vnf mem usage.1', 'vnf sto usage.1', 'vnf before.1',\n",
    "       'vnf after.1', 'sla', 'fg id', 'flow traffic', 'flow latency',\n",
    "       'flow bnd usage', 'flow packet loss', 'min cpu affinity',\n",
    "       'min mem affinity', 'min sto affinity', 'conflicts affinity',\n",
    "       'real_affinity', 'static_affinity', 'predicted_affinity',\n",
    "       'prediction_time', 'TF', 'MTT', 'MTT_upper', 'MTT_lower', 'MTTF_R',\n",
    "       'MTTF_EM', 'MTTF_C', 'MTTF_TDDB', 'MTTF_SM', 'MTTFF_TC', 'A', 'AEM',\n",
    "       'AC', 'ATDDB', 'ASM', 'ATC', 'TAA', 'QRED', 'QR', 'PUE', 'DCie', 'cost',\n",
    "       'TIMESTAMP', 'EXTERNAL_TEMP', 'ROOM_TEMP', 'MTTF_IC', 'A_TC', 'Q_DIT',\n",
    "       'TPF', 'AIRFLOW', 'TAAF', 'DeltaT_de', 'QD']\n",
    "       \n",
    "       \n",
    "#Select your global variable among one of above, and place it after base below\n",
    "\n",
    "\n",
    "base = 'vnf cpu usage'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs = pd.read_csv('../fgs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>4963594775</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>proxy.9.5698</th>\n",
       "      <th>traffic counter.7.5664</th>\n",
       "      <th>0.971442</th>\n",
       "      <th>82.243099</th>\n",
       "      <td>1.794354</td>\n",
       "      <td>9.341767</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402488769</th>\n",
       "      <th>5</th>\n",
       "      <th>1.000000</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traffic counter.7.7413</th>\n",
       "      <th>proxy.9.11244</th>\n",
       "      <th>4.060322</th>\n",
       "      <th>119.086081</th>\n",
       "      <td>16.548350</td>\n",
       "      <td>8.474562</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proxy.9.11244</th>\n",
       "      <th>proxy.9.2362</th>\n",
       "      <th>0.268318</th>\n",
       "      <th>23.865256</th>\n",
       "      <td>11.573841</td>\n",
       "      <td>9.248256</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proxy.9.2362</th>\n",
       "      <th>traffic counter.7.9524</th>\n",
       "      <th>2.961259</th>\n",
       "      <th>80.083566</th>\n",
       "      <td>18.280812</td>\n",
       "      <td>4.783467</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   4963594775  \\\n",
       "proxy.9.5698           traffic counter.7.5664 0.971442 82.243099     1.794354   \n",
       "5402488769             5                      1.000000 NaN                NaN   \n",
       "traffic counter.7.7413 proxy.9.11244          4.060322 119.086081   16.548350   \n",
       "proxy.9.11244          proxy.9.2362           0.268318 23.865256    11.573841   \n",
       "proxy.9.2362           traffic counter.7.9524 2.961259 80.083566    18.280812   \n",
       "\n",
       "                                                                          1  \\\n",
       "proxy.9.5698           traffic counter.7.5664 0.971442 82.243099   9.341767   \n",
       "5402488769             5                      1.000000 NaN              NaN   \n",
       "traffic counter.7.7413 proxy.9.11244          4.060322 119.086081  8.474562   \n",
       "proxy.9.11244          proxy.9.2362           0.268318 23.865256   9.248256   \n",
       "proxy.9.2362           traffic counter.7.9524 2.961259 80.083566   4.783467   \n",
       "\n",
       "                                                                       2  \n",
       "proxy.9.5698           traffic counter.7.5664 0.971442 82.243099   100.0  \n",
       "5402488769             5                      1.000000 NaN           NaN  \n",
       "traffic counter.7.7413 proxy.9.11244          4.060322 119.086081  150.0  \n",
       "proxy.9.11244          proxy.9.2362           0.268318 23.865256   150.0  \n",
       "proxy.9.2362           traffic counter.7.9524 2.961259 80.083566   150.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vns = pd.read_csv('../vnfs.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnf_id = np.array(vns[vns.columns[0]])\n",
    "vnf_type = np.array(vns[vns.columns[1]])\n",
    "vnf_scheduling = np.array(vns[vns.columns[2]])\n",
    "vnf_pm = np.array(vns[vns.columns[3]])\n",
    "vnf_fg = np.array(vns[vns.columns[4]])\n",
    "flavor_data = np.array(vns[vns.columns[5:8]])\n",
    "vm_data = np.array(vns[vns.columns[8:11]])\n",
    "usage_data = np.array(vns[vns.columns[11:15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12322, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv('../new_results_out.csv', sep =';')#header=None)\n",
    "output.drop('Unnamed: 0',axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vnf label</th>\n",
       "      <th>vnf min cpu</th>\n",
       "      <th>vnf min mem</th>\n",
       "      <th>vnf min sto</th>\n",
       "      <th>vnf vm cpu</th>\n",
       "      <th>vnf vm mem</th>\n",
       "      <th>vnf vm sto</th>\n",
       "      <th>vnf pm id</th>\n",
       "      <th>vnf cpu usage</th>\n",
       "      <th>vnf mem usage</th>\n",
       "      <th>...</th>\n",
       "      <th>EXTERNAL_TEMP</th>\n",
       "      <th>ROOM_TEMP</th>\n",
       "      <th>MTTF_IC</th>\n",
       "      <th>A_TC</th>\n",
       "      <th>Q_DIT</th>\n",
       "      <th>TPF</th>\n",
       "      <th>AIRFLOW</th>\n",
       "      <th>TAAF</th>\n",
       "      <th>DeltaT_de</th>\n",
       "      <th>QD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dpi.2.136144</td>\n",
       "      <td>0.035914</td>\n",
       "      <td>0.226393</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.12720</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>257345416</td>\n",
       "      <td>71.88000</td>\n",
       "      <td>1.75780</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>2435.249666</td>\n",
       "      <td>0.996726</td>\n",
       "      <td>1.839678</td>\n",
       "      <td>14.999377</td>\n",
       "      <td>0.131858</td>\n",
       "      <td>0.872117</td>\n",
       "      <td>6.132259</td>\n",
       "      <td>6.132259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traffic counter.7.40368</td>\n",
       "      <td>0.063818</td>\n",
       "      <td>0.017674</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.06189</td>\n",
       "      <td>0.03821</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>3488796635</td>\n",
       "      <td>3.51600</td>\n",
       "      <td>6.34800</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>49.077683</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>1.801941</td>\n",
       "      <td>14.999402</td>\n",
       "      <td>0.142946</td>\n",
       "      <td>0.768427</td>\n",
       "      <td>6.006469</td>\n",
       "      <td>6.006469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proxy.9.13456</td>\n",
       "      <td>0.018672</td>\n",
       "      <td>0.020912</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.01250</td>\n",
       "      <td>0.01590</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>4820294844</td>\n",
       "      <td>0.18044</td>\n",
       "      <td>0.13352</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>82.372536</td>\n",
       "      <td>0.911478</td>\n",
       "      <td>1.800100</td>\n",
       "      <td>54.999420</td>\n",
       "      <td>0.152569</td>\n",
       "      <td>0.757640</td>\n",
       "      <td>6.000332</td>\n",
       "      <td>6.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firewall.3.36933</td>\n",
       "      <td>0.140469</td>\n",
       "      <td>0.021706</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.03198</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>3550430599</td>\n",
       "      <td>26.46000</td>\n",
       "      <td>6.44600</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>0.044220</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>1.814606</td>\n",
       "      <td>39.999481</td>\n",
       "      <td>0.132889</td>\n",
       "      <td>0.807089</td>\n",
       "      <td>6.048686</td>\n",
       "      <td>6.048686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dpi.2.92594</td>\n",
       "      <td>0.015708</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.08569</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>4820072706</td>\n",
       "      <td>41.74000</td>\n",
       "      <td>14.42800</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>1.823040</td>\n",
       "      <td>20.999427</td>\n",
       "      <td>0.189031</td>\n",
       "      <td>0.790021</td>\n",
       "      <td>6.076802</td>\n",
       "      <td>6.076802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 vnf label  vnf min cpu  vnf min mem  vnf min sto  vnf vm cpu  \\\n",
       "0             dpi.2.136144     0.035914     0.226393     0.001757     0.06250   \n",
       "1  traffic counter.7.40368     0.063818     0.017674     0.000223     0.06189   \n",
       "2            proxy.9.13456     0.018672     0.020912     0.000006     0.01250   \n",
       "3         firewall.3.36933     0.140469     0.021706     0.000068     0.09375   \n",
       "4              dpi.2.92594     0.015708     0.050654     0.000810     0.06250   \n",
       "\n",
       "   vnf vm mem  vnf vm sto   vnf pm id  vnf cpu usage  vnf mem usage  ...  \\\n",
       "0     0.12720    0.001930   257345416       71.88000        1.75780  ...   \n",
       "1     0.03821    0.000386  3488796635        3.51600        6.34800  ...   \n",
       "2     0.01590    0.000404  4820294844        0.18044        0.13352  ...   \n",
       "3     0.03198    0.000070  3550430599       26.46000        6.44600  ...   \n",
       "4     0.08569    0.000926  4820072706       41.74000       14.42800  ...   \n",
       "\n",
       "   EXTERNAL_TEMP ROOM_TEMP      MTTF_IC      A_TC     Q_DIT        TPF  \\\n",
       "0             15        23  2435.249666  0.996726  1.839678  14.999377   \n",
       "1             15        24    49.077683  0.859840  1.801941  14.999402   \n",
       "2             55        25    82.372536  0.911478  1.800100  54.999420   \n",
       "3             40        23     0.044220  0.005497  1.814606  39.999481   \n",
       "4             21        29     0.011200  0.001398  1.823040  20.999427   \n",
       "\n",
       "    AIRFLOW      TAAF  DeltaT_de        QD  \n",
       "0  0.131858  0.872117   6.132259  6.132259  \n",
       "1  0.142946  0.768427   6.006469  6.006469  \n",
       "2  0.152569  0.757640   6.000332  6.000332  \n",
       "3  0.132889  0.807089   6.048686  6.048686  \n",
       "4  0.189031  0.790021   6.076802  6.076802  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vnf label', 'vnf min cpu', 'vnf min mem', 'vnf min sto', 'vnf vm cpu',\n",
       "       'vnf vm mem', 'vnf vm sto', 'vnf pm id', 'vnf cpu usage',\n",
       "       'vnf mem usage', 'vnf sto usage', 'vnf before', 'vnf after',\n",
       "       'vnf label.1', 'vnf min cpu.1', 'vnf min mem.1', 'vnf min sto.1',\n",
       "       'vnf vm cpu.1', 'vnf vm mem.1', 'vnf vm sto.1', 'vnf pm id.1',\n",
       "       'vnf cpu usage.1', 'vnf mem usage.1', 'vnf sto usage.1', 'vnf before.1',\n",
       "       'vnf after.1', 'sla', 'fg id', 'flow traffic', 'flow latency',\n",
       "       'flow bnd usage', 'flow packet loss', 'min cpu affinity',\n",
       "       'min mem affinity', 'min sto affinity', 'conflicts affinity',\n",
       "       'real_affinity', 'static_affinity', 'predicted_affinity',\n",
       "       'prediction_time', 'TF', 'MTT', 'MTT_upper', 'MTT_lower', 'MTTF_R',\n",
       "       'MTTF_EM', 'MTTF_C', 'MTTF_TDDB', 'MTTF_SM', 'MTTFF_TC', 'A', 'AEM',\n",
       "       'AC', 'ATDDB', 'ASM', 'ATC', 'TAA', 'QRED', 'QR', 'PUE', 'DCie', 'cost',\n",
       "       'TIMESTAMP', 'EXTERNAL_TEMP', 'ROOM_TEMP', 'MTTF_IC', 'A_TC', 'Q_DIT',\n",
       "       'TPF', 'AIRFLOW', 'TAAF', 'DeltaT_de', 'QD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195379,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[base].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output[:12322]\n",
    "output = output[base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12322,)\n",
      "(12322,)\n",
      "(12322,)\n",
      "(12322,)\n",
      "(12322,)\n",
      "(12322, 3)\n",
      "(12322, 3)\n",
      "(12322, 4)\n"
     ]
    }
   ],
   "source": [
    "thelist = [vnf_id, vnf_type, vnf_scheduling, vnf_pm, vnf_fg, flavor_data, vm_data, usage_data]\n",
    "for i in range(len(thelist)):\n",
    "    print(thelist[i].shape)\n",
    "    if len(thelist[i].shape) == 1:\n",
    "        thelist[i] = np.reshape(thelist[i], (-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnf_id = np.reshape(vnf_id, (-1, 1))\n",
    "vnf_type = np.reshape(vnf_type, (-1, 1))\n",
    "vnf_scheduling = np.reshape(vnf_scheduling, (-1, 1))\n",
    "vnf_pm = np.reshape(vnf_pm, (-1, 1))\n",
    "vnf_fg = np.reshape(vnf_fg, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12322, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnf_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputt = np.concatenate((vnf_id, vnf_type, vnf_scheduling, vnf_pm, vnf_fg, flavor_data, vm_data, usage_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12322, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, testx, trainy, testy = train_test_split(inputt, output, test_size=0.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainx shape (10104, 15)\n",
      "Trainy shape (10104,)\n",
      "Testx shape (2218, 15)\n",
      "Testy shape (2218,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainx shape\", trainx.shape)\n",
    "print(\"Trainy shape\", trainy.shape)\n",
    "print(\"Testx shape\", testx.shape)\n",
    "print(\"Testy shape\", testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.gcd(10104, 2218)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = np.array(trainx)\n",
    "trainy = np.array(trainy)\n",
    "testx = np.array(testx)\n",
    "testy = np.array(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping data for LSTM\n",
    "\n",
    "trainx = trainx.reshape((-1, 2, 15))\n",
    "trainy = trainy.reshape((-1, 2))\n",
    "testx = testx.reshape((-1, 2, 15))\n",
    "testy = testy.reshape((-1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Construction of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "no_units = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.placeholder(dtype=tf.float32, shape=[None, 2, 15])\n",
    "target = tf.placeholder(dtype = tf.float32, shape = [None, 2])\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0726 11:18:28.102379 140527127572608 deprecation.py:323] From <ipython-input-28-805daaeb55b3>:3: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
      "W0726 11:18:28.103054 140527127572608 deprecation.py:323] From <ipython-input-28-805daaeb55b3>:3: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
      "W0726 11:18:28.108556 140527127572608 deprecation.py:323] From /usr/local/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "W0726 11:18:28.109143 140527127572608 deprecation.py:323] From /usr/local/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "W0726 11:18:28.109593 140527127572608 deprecation.py:323] From /usr/local/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train, target)).batch(batch_size).repeat()\n",
    "test_dataset = tf.data.Dataset.from_tensors((train, target)).repeat()\n",
    "iterr = tf.data.Iterator.from_structure(dataset.output_types, dataset.output_shapes)\n",
    "inputt, outputt = iterr.get_next()\n",
    "\n",
    "#Creating Initialization operations\n",
    "train_init_op = iterr.make_initializer(dataset)\n",
    "test_init_op = iterr.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = math.ceil(trainx.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Forward and Backward Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 11:18:29.621497 140527127572608 deprecation.py:506] From /usr/local/lib/python3.5/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0726 11:18:29.624227 140527127572608 deprecation.py:323] From <ipython-input-30-9000bcacb521>:1: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0726 11:18:29.625959 140527127572608 deprecation.py:323] From <ipython-input-30-9000bcacb521>:5: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "lstm_fw = [tf.nn.rnn_cell.LSTMCell(num_units = no_units, initializer=tf.keras.initializers.glorot_normal(), state_is_tuple=True)]\n",
    "lstm_bw = [tf.nn.rnn_cell.LSTMCell(num_units = no_units, initializer=tf.keras.initializers.glorot_normal(), state_is_tuple=True)]\n",
    "\n",
    "for i in range(2):\n",
    "    lstm_fw.append(tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.LSTMCell(num_units=no_units, initializer=tf.keras.initializers.glorot_normal(), state_is_tuple=True)]))\n",
    "    lstm_bw.append(tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.LSTMCell(num_units=no_units, initializer=tf.keras.initializers.glorot_normal(), state_is_tuple=True)]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 11:18:31.516993 140527127572608 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0726 11:18:31.520122 140527127572608 deprecation.py:323] From /usr/local/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/rnn.py:239: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "W0726 11:18:31.521269 140527127572608 deprecation.py:323] From /usr/local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0726 11:18:31.604693 140527127572608 deprecation.py:506] From /usr/local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "encoder_outputs, encoder_fw_state, encoder_bw_state = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\n",
    "                                                    cells_fw=lstm_fw,\n",
    "                                                    cells_bw = lstm_bw,\n",
    "                                                    inputs = inputt,\n",
    "                                                    dtype = tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_state_c = tf.concat((encoder_fw_state[-1][0].c, encoder_bw_state[-1][0].c), 1)\n",
    "\n",
    "encoder_state_h = tf.concat((encoder_fw_state[-1][0].h, encoder_bw_state[-1][0].h), 1)\n",
    "\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=encoder_state_c,\n",
    "    h=encoder_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.layers.Dense(2)(encoder_state_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 11:18:32.969033 140527127572608 deprecation.py:323] From /usr/local/lib/python3.5/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.mean_squared_error(outputt, output)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('tmp'):\n",
    "    os.makedirs('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 11:18:36.671230 140527127572608 deprecation.py:323] From <ipython-input-37-b69629eb4301>:6: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\n2 root error(s) found.\n  (0) Not found: Key dense/bias/Adam not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-37-b69629eb4301>:2) ]]\n  (1) Not found: Key dense/bias/Adam not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-37-b69629eb4301>:2) ]]\n\t [[save/RestoreV2/_7]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"/usr/local/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.5/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-b69629eb4301>\", line 2, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 825, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: Key dense/bias/Adam not found in checkpoint\n\t [[{{node save/RestoreV2}}]]\n  (1) Not found: Key dense/bias/Adam not found in checkpoint\n\t [[{{node save/RestoreV2}}]]\n\t [[save/RestoreV2/_7]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1286\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: Key dense/bias/Adam not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-37-b69629eb4301>:2) ]]\n  (1) Not found: Key dense/bias/Adam not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-37-b69629eb4301>:2) ]]\n\t [[save/RestoreV2/_7]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"/usr/local/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.5/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-b69629eb4301>\", line 2, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 825, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1295\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m   \u001b[0mobject_graph_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJECT_GRAPH_PROTO_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m   \u001b[0mobject_graph_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrackable_object_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableObjectGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader_GetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b69629eb4301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp/model_tensorflow.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tmp/model_tensorflow.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model Restored\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     sess.run(iter.initializer, feed_dict={train: x, target: y})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1302\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\n2 root error(s) found.\n  (0) Not found: Key dense/bias/Adam not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-37-b69629eb4301>:2) ]]\n  (1) Not found: Key dense/bias/Adam not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-37-b69629eb4301>:2) ]]\n\t [[save/RestoreV2/_7]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"/usr/local/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.5/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-b69629eb4301>\", line 2, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 825, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "losx = []\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    if(tf.train.checkpoint_exists('tmp/model_tensorflow.ckpt')):\n",
    "        saver.restore(sess, 'tmp/model_tensorflow.ckpt')\n",
    "        print(\"Model Restored\")\n",
    "#     sess.run(iter.initializer, feed_dict={train: x, target: y})\n",
    "    sess.run(train_init_op, feed_dict={train: trainx, target: trainy})\n",
    "    for i in range(epochs):\n",
    "        for _ in range(n_batches):\n",
    "                lossx, idk = sess.run([loss, train_op])\n",
    "                losx.append([loss])                   \n",
    "        print(\"Current epoch going on is...\",i,\"and current loss is...\", lossx)\n",
    "    save_path = saver.save(sess, 'tmp/model_tensorflow.ckpt')\n",
    "    print(\"Model saved in path: %s\"%save_path)\n",
    "    \n",
    "    print(\"Now commencing, testing\")\n",
    "    sess.run(test_init_op, feed_dict = {train:testx, target:testy})\n",
    "    print(\"Test loss: {:4f}\".format(sess.run(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    if(tf.train.checkpoint_exists('tmp/model_tensorflow.ckpt')):\n",
    "        saver.restore(sess, 'tmp/model_tensorflow.ckpt')\n",
    "        print(\"Model Restored\")\n",
    "#     sess.run(iter.initializer, feed_dict={train: x, target: y})\n",
    "    sess.run(test_init_op, feed_dict = {train:testx, target:testy})\n",
    "    print(\"Test loss: {:4f}\".format(sess.run(loss)))\n",
    "    prediction = sess.run(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
